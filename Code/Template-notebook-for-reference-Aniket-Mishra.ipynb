{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# importing all required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing all required libraries\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "#for removing those red color clueless warning blocks\n",
    "import wanings\n",
    "warnings.filter.warnings('ignore')\n",
    "\n",
    "\n",
    "#for pre-processing\n",
    "#1. for encoding--->>>>>>>>>>>>>i am always using labelencoder so i ont need to import labelEncoder\n",
    "#2. for scaling\n",
    "#a....one maethod is standardScaling  other is MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "#for train-test split\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#for making models\n",
    "#1.for LinearRegression---SAME FOR MULTIPLe regression\n",
    "from sklearn.linear_model import LinearRegression\n",
    "#2. for LogisticRegression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "#3. for DecisionTree\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "#4. for kNeighbors\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "#5. for svm\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "#importing non supervised learning models\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "#checking the model\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "# ensemble techniques\n",
    "#bagging\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "#boosting\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "#cross-validation k-folds\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# reading dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_name=pd.read_csv('datasetfinename.csv')\n",
    "df_name=pd.read_excel('datasetfinename.xls')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# checking for missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_name.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# extracting info about dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_name.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_name.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#using value_counts\n",
    "df_name['col_name'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Statistical properties of all columns\n",
    "dataframe.mean()\n",
    "dataframe.std()\n",
    "dataframe.median()\n",
    "dataframe.var()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#group dataframe by category\n",
    "dataframe_groupedBy_Target_cATEGORY=df_name.groupby('categoryColumn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#getting unique values\n",
    "unique_values = dataframe['column'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#To remove all null values \n",
    "#DONT DO THIS OKIEEE\n",
    "dataframe.dropna(inplace =True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# check for categorical and numerical variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for dsiplaying all columns\n",
    "col=df_name.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#to get datatype of a particular column\n",
    "dataframe['column'].dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### getting categorical columns in a index type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#getting categorical columns in a index type\n",
    "categorical_cols=df_name.select_dtypes(include=['object']).columns\n",
    "categorical_cols\n",
    "#from this you can copy the columns you want to make a list\n",
    "#bit of hard coding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### getting numerical columns in a index type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#getting numerical columns in a index type\n",
    "numerical_columns=df_name.select_dtypes(include=['int64','float64']).columns\n",
    "numerical_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# treating missing values through fillna imputations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### mode calculation for categorical columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_name[categorical_cols].mode()\n",
    "#--------------------------------------------------\n",
    "ar_of_modes=np.array(df[categorical_cols].mode())\n",
    "val=ar_of_modes[0]\n",
    "val\n",
    "#-------------------------------------------------\n",
    "#filling with mode\n",
    "f=0\n",
    "for i in categorical_cols:\n",
    "    df[i]=df[i].fillna(val[f])\n",
    "    f+=1\n",
    "#------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### median calculation for numerical column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_name[categorical_cols].median()\n",
    "#--------------------------------------------------\n",
    "v=np.array(df[numerical_columns].median(skipna=True))\n",
    "v\n",
    "#-------------------------------------------------\n",
    "#filling with median\n",
    "f=0\n",
    "for i in cols_for_median_replace:\n",
    "    df[i]=df[i].fillna(v[f])\n",
    "    f+=1\n",
    "#---------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#using factorize values\n",
    "for i in categorical_cols:\n",
    "    df[i]=pd.factorize(df[i])[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_max_scaler=MinMaxScaler()\n",
    "std_scaler=StandardScaler()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[cols1]=std_scaler.fit_transform(df[cols1])\n",
    "df[cols1]=min_max_scaler.fit_transform(df[cols1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# finding correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.corr()\n",
    "#creating heatmap\n",
    "plt.figure(figsize=(20,18))\n",
    "cor=df.corr()\n",
    "sns.heatmap(df.corr(),annot=True)\n",
    "plt.show()\n",
    "#correlation with output variable\n",
    "cor_target=abs(cor['final_category_column'])\n",
    "print(cor_target.sort_values())\n",
    "#selecting highly correlated features\n",
    "relevant_features=cor_target[cor_target>0.7]\n",
    "relevant_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# finding variations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.var().sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "variance_val=hrs.var().sort_values()\n",
    "variance_val=pd.DataFrame(variance_val).T\n",
    "variance_val\n",
    "variance_val.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# spliting train and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train,df_test=train_test_split(df,test_size=0.2,random_state=42)\n",
    "print(df_train.shape)\n",
    "print(df_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# feature and target selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features=['','','']  #give column names #type is list\n",
    "target=['']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dont do this\n",
    "feature_col=list(df.drop(['col1','categoryColumn'],axis=1))\n",
    "features=[feature_col]\n",
    "target=['categoryColumn']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataframe \n",
    "x=df[feature_col]\n",
    "y=df['categoryColumn']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ---------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# pca features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataframe \n",
    "x=df[feature_col]\n",
    "y=df['categoryColumn']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca=PCA(0.95)\n",
    "x_pca=pca.fit_transform(x)\n",
    "x_pca.shape\n",
    "pca.explained_variance_ratio_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# for logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_lr=LogisticRegression()\n",
    "x_train,x_test,y_train,y_test=train_test_split(x_pca,y,test_size=0.2,random_state=42)\n",
    "model_lr.fit(x_train,y_train)\n",
    "y_predict=model_lr.predict(x_test)\n",
    "print(confusion_matrix(y_test,y_predict))\n",
    "print(classification_report(y_test,y_predict))\n",
    "model_lr.score(x_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# for decision tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_tree=DecisionTreeClassifier()\n",
    "model_tree.fit(x_train,y_train)\n",
    "y_predict=model_tree.predict(x_test)\n",
    "print(confusion_matrix(y_test,y_predict))\n",
    "print(classification_report(y_test,y_predict))\n",
    "model_tree.score(x_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# knn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_n=KNeighborsClassifier(n_neighbors=2)\n",
    "knn_n.fit(x_train,y_train)\n",
    "y_predict=knn_n.predict(x_test)\n",
    "print(classification_report(y_test,y_predict))\n",
    "print(confusion_matrix(y_test,y_predict))\n",
    "knn_n.score(x_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_m=SVC(kernel='rbf')\n",
    "svm_m.fit(x_train,y_train)\n",
    "y_pred=svm_m.predict(x_test)\n",
    "print(classification_report(y_test,y_predict))\n",
    "print(confusion_matrix(y_test,y_predict))\n",
    "svm_m.score(x_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# cross-validation k folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# logistic regression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg=LogisticRegression()\n",
    "log_reg=cross_val_score(logreg,x_pca,y,cv=10,scoring='accuracy').mean()\n",
    "print(log_reg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# knn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kn=KNeighborsClassifier(n_neighbors=3)\n",
    "kn_n=cross_val_score(kn,x_pca,y,cv=10,scoring='accuracy').mean()\n",
    "print(kn_n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_svm=SVC(kernel=\"rbf\")\n",
    "sv_m=cross_val_score(model_svm,x_pca,y,cv=10,scoring='accuracy').mean()\n",
    "print(sv_m)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# decision trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_tree=DecisionTreeClassifier()\n",
    "d_T=cross_val_score(model_tree,x_pca,y,cv=10,scoring='accuracy').mean()\n",
    "print(d_T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# -----------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ensemble techniques"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### bagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=RandomForestClassifier(n_estimators=10,min_samples_split=20,min_impurity_decrease=0.05)\n",
    "model.fit(x_train,y_train)\n",
    "print(model.score(x_test,y_test))\n",
    "print(model.score(x_train,y_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_ada=AdaBoostClassifier(n_estimators=10)\n",
    "model.fit(x_train,y_train)\n",
    "train_accuracy=model.score(x_train,y_train)\n",
    "test_accuracy=model.score(x_test,y_test)\n",
    "print(model.score(x_test,y_test))\n",
    "print(model.score(x_train,y_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# feature and its importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features=pd.DataFrame(np.array([X.columns,ensemble_model.feature_importances_]).T,columns=[\"feature\",\"importance\"])\n",
    "features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ----------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RFE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_selection import RFE\n",
    "model_log=LogisticRegression()\n",
    "selector=RFE(model_log,3)#SELECT 3 FEATURES\n",
    "#----------------------------------------------------\n",
    "#----------------------------------------------------\n",
    "#here x and y are the dataframes\n",
    "x = df1.loc[:,'radius_mean':'dimension_worst']\n",
    "y = df1[\"diagnosised\"]\n",
    "#--------------------------------------------------\n",
    "#--------------------------------------------------\n",
    "selector=selector.fit(x,y) #just like model.fit\n",
    "selector.support_  #shows features which are selected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.columns #support_ gives t/f only so map these results for hetting column names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating x y new df's\n",
    "X=df1[['points_mean','radius_worst','points_worst']]\n",
    "y=df1['diagnosised']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "#----------------------------------------------------------------\n",
    "X_test,X_train,y_test,y_train=train_test_split(X,y,test_size=0.2,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_log.fit(X_train,y_train)\n",
    "pred=model_log.predict(X_test)\n",
    "model_log.score(X_train,y_train)\n",
    "model_log.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix,mean_squared_error\n",
    "mean_squared_error(y_test,pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# root mean square"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k=np.sqrt(mean_squared_error(y_test,pred))\n",
    "k"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ---------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "lda=LDA(n_components=3)\n",
    "x_new=lda.fit_transform(x,y)\n",
    "x_new.shape\n",
    "X_train,X_test,y_train,y_test=train_test_split(x_new,y,test_size=0.2,random_state=42)\n",
    "#LDA WITH SVM \n",
    "#------------------------------------\n",
    "model_svc=SVC(kernel=\"rbf\")\n",
    "model_svc.fit(X_train,y_train)\n",
    "pred=model_svc.predict(X_test)\n",
    "model_svc.score(X_train,y_train)\n",
    "#-------------------------------------\n",
    "model_svc.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ---------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FROM CLUSTERS kmeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "kmeans = KMeans(n_clusters=2)\n",
    "df_analyze = df.drop('id',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
